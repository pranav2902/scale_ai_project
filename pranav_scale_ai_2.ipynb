{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranav2902/scale_ai_project/blob/main/pranav_scale_ai_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7F5MPfT62_p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4haDFPjI6-G8"
      },
      "outputs": [],
      "source": [
        "batch_size = 256  # Batch size for training.\n",
        "epochs = 20  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "data_path = \"/content/drive/MyDrive/polynomial/train.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa1z5DAP7Bkg",
        "outputId": "ebecaa1f-628f-45d8-8bb1-399b1ff162f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 1000000\n",
            "Number of unique input tokens: 28\n",
            "Number of unique output tokens: 30\n",
            "Max sequence length for inputs: 29\n",
            "Max sequence length for outputs: 30\n",
            "{'(': 0, ')': 1, '*': 2, '+': 3, '-': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, 'a': 15, 'c': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'n': 21, 'o': 22, 's': 23, 't': 24, 'x': 25, 'y': 26, 'z': 27}\n"
          ]
        }
      ],
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: len(lines) - 1]:\n",
        "    input_text, target_text = line.split(\"=\")\n",
        "    # We use \"=\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"=\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "print(input_token_index)\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    #encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    #decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    #decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA2NVPDu7FJX"
      },
      "outputs": [],
      "source": [
        "#Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True,dropout = 0.1)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, dropout = 0.5)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIvNH6488YYu",
        "outputId": "4e37e2b3-a8f8-49d2-c692-0484054f8f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3125/3125 [==============================] - 903s 288ms/step - loss: 0.8529 - accuracy: 0.3410 - val_loss: 0.5793 - val_accuracy: 0.8278\n",
            "Epoch 2/20\n",
            "3125/3125 [==============================] - 1066s 341ms/step - loss: 0.5646 - accuracy: 0.8418 - val_loss: 0.4857 - val_accuracy: 0.8737\n",
            "Epoch 3/20\n",
            "3125/3125 [==============================] - 936s 299ms/step - loss: 0.4943 - accuracy: 0.8679 - val_loss: 0.4216 - val_accuracy: 0.8901\n",
            "Epoch 4/20\n",
            "3125/3125 [==============================] - 876s 280ms/step - loss: 0.4638 - accuracy: 0.8749 - val_loss: 0.3994 - val_accuracy: 0.8943\n",
            "Epoch 5/20\n",
            "3125/3125 [==============================] - 886s 284ms/step - loss: 0.4459 - accuracy: 0.8798 - val_loss: 0.3887 - val_accuracy: 0.8978\n",
            "Epoch 6/20\n",
            "3125/3125 [==============================] - 881s 282ms/step - loss: 0.4304 - accuracy: 0.8849 - val_loss: 0.3794 - val_accuracy: 0.9045\n",
            "Epoch 7/20\n",
            "3125/3125 [==============================] - 889s 284ms/step - loss: 0.4183 - accuracy: 0.8896 - val_loss: 0.3599 - val_accuracy: 0.9099\n",
            "Epoch 8/20\n",
            "3125/3125 [==============================] - 923s 295ms/step - loss: 0.4082 - accuracy: 0.8924 - val_loss: 0.3532 - val_accuracy: 0.9117\n",
            "Epoch 9/20\n",
            "3125/3125 [==============================] - 980s 313ms/step - loss: 0.3999 - accuracy: 0.8940 - val_loss: 0.3500 - val_accuracy: 0.9106\n",
            "Epoch 10/20\n",
            "3125/3125 [==============================] - 984s 315ms/step - loss: 0.3917 - accuracy: 0.8959 - val_loss: 0.3418 - val_accuracy: 0.9139\n",
            "Epoch 11/20\n",
            "3125/3125 [==============================] - 960s 307ms/step - loss: 0.3834 - accuracy: 0.8982 - val_loss: 0.3435 - val_accuracy: 0.9124\n",
            "Epoch 12/20\n",
            "3125/3125 [==============================] - 965s 309ms/step - loss: 0.3780 - accuracy: 0.8994 - val_loss: 0.3324 - val_accuracy: 0.9144\n",
            "Epoch 13/20\n",
            "3125/3125 [==============================] - 934s 299ms/step - loss: 0.3708 - accuracy: 0.9007 - val_loss: 0.3164 - val_accuracy: 0.9192\n",
            "Epoch 14/20\n",
            "3125/3125 [==============================] - 928s 297ms/step - loss: 0.3651 - accuracy: 0.9015 - val_loss: 0.3203 - val_accuracy: 0.9170\n",
            "Epoch 15/20\n",
            "3125/3125 [==============================] - 938s 300ms/step - loss: 0.3604 - accuracy: 0.9024 - val_loss: 0.3045 - val_accuracy: 0.9212\n",
            "Epoch 16/20\n",
            "3125/3125 [==============================] - 954s 305ms/step - loss: 0.3567 - accuracy: 0.9028 - val_loss: 0.3007 - val_accuracy: 0.9215\n",
            "Epoch 17/20\n",
            "3125/3125 [==============================] - 972s 311ms/step - loss: 0.3509 - accuracy: 0.9040 - val_loss: 0.2942 - val_accuracy: 0.9242\n",
            "Epoch 18/20\n",
            "3125/3125 [==============================] - 1060s 339ms/step - loss: 0.3480 - accuracy: 0.9043 - val_loss: 0.2953 - val_accuracy: 0.9225\n",
            "Epoch 19/20\n",
            "3125/3125 [==============================] - 910s 291ms/step - loss: 0.3431 - accuracy: 0.9051 - val_loss: 0.3005 - val_accuracy: 0.9205\n",
            "Epoch 20/20\n",
            "3125/3125 [==============================] - 859s 275ms/step - loss: 0.3417 - accuracy: 0.9052 - val_loss: 0.2887 - val_accuracy: 0.9225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_pranav_20ep_modularized_dropout/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_pranav_20ep_modularized_dropout/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8c25144550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8bfaf72050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "# Tried rmsprop before, try adam next\n",
        "\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"model_pranav_20ep_modularized_dropout\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/model_pranav_20ep_modularized_dropout.zip /content/model_pranav_20ep_modularized_dropout\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I23O7aWJQnN4",
        "outputId": "b23549fa-2c3c-4906-d7b8-2b460e00636a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/model_pranav_20ep_modularized_dropout/ (stored 0%)\n",
            "  adding: content/model_pranav_20ep_modularized_dropout/variables/ (stored 0%)\n",
            "  adding: content/model_pranav_20ep_modularized_dropout/variables/variables.index (deflated 62%)\n",
            "  adding: content/model_pranav_20ep_modularized_dropout/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/model_pranav_20ep_modularized_dropout/keras_metadata.pb (deflated 90%)\n",
            "  adding: content/model_pranav_20ep_modularized_dropout/saved_model.pb (deflated 91%)\n",
            "  adding: content/model_pranav_20ep_modularized_dropout/assets/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/model_pranav_20ep_modularized_dropout.zip -d /content/model_pranav_20ep_modularized_dropout\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_rrNa13RFg8",
        "outputId": "bd1a8078-8e30-4355-89cc-3bd4f82cbc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/model_pranav_20ep_modularized_dropout.zip\n",
            "   creating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/\n",
            "   creating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/variables/\n",
            "  inflating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/variables/variables.index  \n",
            "  inflating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/variables/variables.data-00000-of-00001  \n",
            "  inflating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/keras_metadata.pb  \n",
            "  inflating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/saved_model.pb  \n",
            "   creating: /content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/model_pranav_20ep_modularized_dropout/content/model_pranav_20ep_modularized_dropout')"
      ],
      "metadata": {
        "id": "P_Z1TNO2ol3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSjZZxJWo43z",
        "outputId": "deae2d73-2958-451b-9c18-4d292a957701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 28)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 30)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        291840      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  293888      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 30)     7710        ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 593,438\n",
            "Trainable params: 593,438\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model weights\n",
        "weights_file = open(\"weights.txt\", \"w+\")\n",
        "for layer in model.layers:\n",
        "    weights_file.write(str(layer.get_weights()))\n",
        "    weights_file.write(\"\\n\")\n",
        "weights_file.close()"
      ],
      "metadata": {
        "id": "-k77VnUSpOH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/MySubmission.zip /content/MySubmission\n"
      ],
      "metadata": {
        "id": "6xQARLOhp5Nc",
        "outputId": "7e0c3fce-6416-498d-a11a-308fc8675a5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/MySubmission/ (stored 0%)\n",
            "  adding: content/MySubmission/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/MySubmission/network.txt (deflated 84%)\n",
            "  adding: content/MySubmission/weights.txt (deflated 64%)\n",
            "  adding: content/MySubmission/requirements.txt (stored 0%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "pranav_scale_ai_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}